{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xs6XZAf7wmKe"
   },
   "source": [
    "# Instructions to reproduce the results on GCP\n",
    "\n",
    "### GPU:\n",
    "\n",
    "- Go to [AI platform notebooks](https://cloud.google.com/ai-platform-notebooks/)\n",
    "- Press \"Go to console\". If you don't see \"Go to console\" you need to create\n",
    "  a GCP account for free:\n",
    "    -  Press \"Get started for free\" and create an account.\n",
    "    - Open [AI platform notebooks](https://cloud.google.com/ai-platform-notebooks/)\n",
    "    - Press \"Go to console\"\n",
    "    - Press \"Enable API\"\n",
    "    - Wait for the previous step to finish and press \"GO TO INSTANCES PAGE\"\n",
    "- Press \"New Insance\" at the top -> \"Customize instance\".\n",
    "- Create a new instance with the following specifications:\n",
    "    - Region: **us-central1**\n",
    "    - Zone: **us-central1-b** (this is important for TPU)\n",
    "    - Environment: TensorFlow 2.1 Enterprise\n",
    "    - Machine type: `n1-highcpu-96` (96 vCPUs, 86.4 GB RAM)\n",
    "    - GPU Type: NVIDIA TESLA v100 GPU\n",
    "    - Tick \"install NVIDIA GPU driver\"\n",
    "    - Press create\n",
    "    - Press JUPYTERLAB and upload this notebook\n",
    "\n",
    "\n",
    "### TPU:\n",
    "- Follow the steps from from above but the GPU set up may be omitted\n",
    "- Go to [Compute Engine -> TPUs](https://pantheon.corp.google.com/compute/tpus)\n",
    "- Follow the hints to create a TPU node with the following specs:\n",
    "     -  Zone: **us-central1-b**\n",
    "     - TPU type: `v2-8` (you can use `v3-8` for better performance)\n",
    "     - TPU software version: `nightly`\n",
    "     - Press \"create\"\n",
    "- Wait for the node to start up. Take a note of the internal IP (something like `10.245.84.146`)\n",
    "- Open the JUPYTERLAB created by the steps above.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfMDV86aLmJJ"
   },
   "source": [
    "# Notes\n",
    "\n",
    "In this colab we perform CVA-like calculation for a batch of vanilla interest \n",
    "rate swaps. We assume an underlying Hull-White model for a short rate.\n",
    "We propagate the rate for 136 steps and price 1 million swaps at each iteration.\n",
    "The swaps have tenures of up to 30 years with payment frequencies varying from\n",
    "1 to 12 months. \n",
    "\n",
    "The whole procedure takes **3 seconds** on a **TPU**. This is currently done in a single precision but should be shortly be available in double precision too. \n",
    "\n",
    "We compare sampling speed against CPU and GPU and provide a reference to QuantLib sampling speed.\n",
    "\n",
    "\n",
    "# Hull White future yield curves.\n",
    "\n",
    "For the single factor Hull white model, the conditional forward bond prices are of the [affine form](https://en.wikipedia.org/wiki/Hull%E2%80%93White_model#Bond_pricing_using_the_Hull%E2%80%93White_model):\n",
    "\n",
    "$$P(S, T) = A(S, T) e^{-B(S,T) r(S)}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$B(S, T) = \\frac{1}{\\alpha} \\left(1 - e^{-\\alpha (T-S) } \\right)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\ln A(S, T) &=& \\ln \\frac{P(0, T)}{P(0, S)} + B(S, T) f(0, S) - \\frac{\\sigma^2}{4\\alpha^3}\\left[1-e^{-\\alpha (T-S)}\\right]^2 (1-e^{-2\\alpha S}) \\\\\n",
    "&=& \\ln \\frac{P(0, T)}{P(0, S)} + B(S, T) f(0, S) - \\frac{\\sigma^2}{4\\alpha}B(S,T)^2 (1-e^{-2\\alpha S})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "and\n",
    "$$f(0, S) = -\\frac{\\partial}{\\partial S} \\ln P(0, S)$$\n",
    "\n",
    "Assuming we are given the pair $(S, r(S))$, we can use the above to compute the discount factors as \"observed\" at time $S$. The set of future times will be given to us and the $r$ at those times will be computed by sampling (see next section.).t those times will be computed by sampling (see next section.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yl_1VMj-Y4vI"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "import time\n",
    "\n",
    "# Disable eager execution since TPU routines are better handled in graph mode\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import tf_quant_finance as tff\n",
    "\n",
    "# Load TFF dates library\n",
    "dates = tff.experimental.dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9Bi7uvGZTe4"
   },
   "outputs": [],
   "source": [
    "#@title Global dtype. TPU will soon support FP64\n",
    "dtype = np.float32 #@param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "jUfY_a1et1h8"
   },
   "outputs": [],
   "source": [
    "#@title TFF Fixing funtion and VanillaSwap class\n",
    "\n",
    "def get_fixings(*, dates_tensor, discount_fn, day_count, dtype):\n",
    "  \"\"\"Computes fixings implied by the input dates tensor and a discounting curve.\n",
    "\n",
    "  Given dates `[d1, d2, .. , dn]` computes forward rates `fwd_rates` between\n",
    "  `[d_i, d_{i+1}]` for `i=0,..., n-1` and returns the corresponding deposit\n",
    "  rates defined as `1 + deposit_rates * day_count(d_i, d_{i+1}) = fwd_rates`.\n",
    "\n",
    "  Args:\n",
    "    dates_tensor: `DateTensor` of shape `[num_dates, batch_shape]`.\n",
    "    discount_fn: A callable that maps `DateTensor` to a real number of `dtype`\n",
    "      which corresponds to discounting.\n",
    "    day_count: A daycounting function.\n",
    "    dtype: Output `dtype`.\n",
    "  \n",
    "  Returns:\n",
    "    A `Tensor` of the specified `dtype` and of shape\n",
    "    `[num_dates - 1, batch_shape]` that correponds to the deposit rates at\n",
    "    `dates_tensor[1:]`.\n",
    "  \"\"\" \n",
    "  start_dates = dates_tensor[:-1]\n",
    "  end_dates = dates_tensor[1:]\n",
    "  disc_start = discount_fn(start_dates)\n",
    "  disc_end = discount_fn(end_dates)\n",
    "  t = day_count(start_date=start_dates, end_date=end_dates, dtype=dtype)\n",
    "  if t.shape.as_list() != disc_end.shape.as_list():\n",
    "    t = tf.expand_dims(t, axis=-1)\n",
    "  fixings = (disc_start/disc_end - 1.0) / t\n",
    "  fixings = tf.where(t > 0, fixings, 0)\n",
    "  return fixings\n",
    "\n",
    "class VanillaSwap:\n",
    "  \"\"\"Simple interest rate swap.\"\"\"\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               calc_date,\n",
    "               fixed_leg_dates,\n",
    "               float_leg_dates,\n",
    "               fixed_leg_rates,\n",
    "               float_leg_rates,\n",
    "               notional,\n",
    "               day_count,\n",
    "               discount_fn,\n",
    "               dtype=None):\n",
    "    \"\"\"Initializer.\n",
    "    \n",
    "    Args:\n",
    "      calc_date: An instance of `DateTensor` of zero shape. The reference date\n",
    "        to which perform the discounting.\n",
    "      fixed_leg_dates: A `DateTensor` of shape `[batch_shape, n]` representing\n",
    "        the cashflow dates of the fixed leg including the `calc_date` as the\n",
    "        first entry for each swap in the batch.\n",
    "      float_leg_dates: A `DateTensor` of shape `[batch_shape, n]` representing\n",
    "        the cashflow dates of the float leg including the `calc_date` as the\n",
    "        first entry for each swap in the batch. \n",
    "      fixed_leg_rates: A real `Tensor` of shape brodcastable with\n",
    "        `[batch_shape, n]` representing the fixed rates of the swap.\n",
    "      float_leg_rates: A real `Tensor` of shape brodcastable with\n",
    "        `[batch_shape, n]` and of the same dtype as `fixed_leg_rates`.\n",
    "        Represents the float rates of the swap.\n",
    "      notional: A real `Tensor` of shape brodcastable with `[batch_shape, n]`\n",
    "        and of the same dtype as `fixed_leg_rates`. Represents the notional of\n",
    "        the swap.\n",
    "      day_count: A daycount convention. One of `dates.daycounts`.\n",
    "      discount_fn: A callable that maps `DateTensor` to a real number of the\n",
    "        same `dtype` as `fixed_leg_rates` which corresponds to the discounting\n",
    "        function.\n",
    "      dtype: A `dtype` for the underlying real `Tensor`s.\n",
    "        Default value: None which maps to the `dtype` inferred by TensorFlow.\n",
    "    \"\"\"  \n",
    "    self._calc_date = calc_date\n",
    "    self._fixed_leg_dates= fixed_leg_dates\n",
    "    self._float_leg_dates = float_leg_dates\n",
    "    self._fixed_leg_rates = fixed_leg_rates\n",
    "    self._float_leg_rates = float_leg_rates\n",
    "    self._notional = notional\n",
    "    self._day_count = day_count\n",
    "    self._discount_fn = discount_fn\n",
    "    self._dtype = dtype\n",
    "\n",
    "  def fixed_cashflows(self):\n",
    "    \"\"\"Returns all fixed cashflows at `fixed_leg_dates`.\"\"\"\n",
    "    start_dates = self._fixed_leg_dates[:-1]\n",
    "    end_dates = self._fixed_leg_dates[1:]\n",
    "    t = self._day_count(\n",
    "        start_date=start_dates, end_date=end_dates, dtype=self._dtype)\n",
    "    t = tf.nn.relu(t)\n",
    "    if t.shape.as_list() != self._float_leg_rates.shape.as_list():\n",
    "      t = tf.expand_dims(t, axis=-1)\n",
    "    return self._notional * self._fixed_leg_rates * t\n",
    "\n",
    "  def float_cashflows(self):\n",
    "    \"\"\"Returns all float cashflows at `float_leg_dates`.\"\"\"\n",
    "    start_dates = self._float_leg_dates[:-1]\n",
    "    end_dates = self._float_leg_dates[1:]\n",
    "    t = self._day_count(\n",
    "        start_date=start_dates, end_date=end_dates, dtype=self._dtype)\n",
    "    t = tf.nn.relu(t)\n",
    "    if t.shape.as_list() != self._float_leg_rates.shape.as_list():\n",
    "      t = tf.expand_dims(t, axis=-1)\n",
    "    return self._notional * self._float_leg_rates * t\n",
    "\n",
    "  def float_leg_present_value(self):\n",
    "    \"\"\"Returns the value of the float leg discounted to `self.calc_date`.\"\"\"\n",
    "    payment_dates = self._float_leg_dates[1:]\n",
    "    cashflows = self.float_cashflows()\n",
    "    return tf.reduce_sum(cashflows * self._discount_fn(payment_dates),\n",
    "                         axis=0)\n",
    "\n",
    "  def fixed_leg_present_value(self):\n",
    "    \"\"\"Returns the value of the fixed leg discounted to `self.calc_date`.\"\"\"\n",
    "    payment_dates = self._fixed_leg_dates[1:]\n",
    "    cashflows = self.fixed_cashflows()\n",
    "    return tf.reduce_sum(cashflows * self._discount_fn(payment_dates),\n",
    "                         axis=0)\n",
    "\n",
    "  def price(self):\n",
    "    \"\"\"Returns the value of the swap discounted to `self.calc_date`.\"\"\"\n",
    "    return self.float_leg_present_value() - self.fixed_leg_present_value()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "YCPKrVeq9M8p"
   },
   "outputs": [],
   "source": [
    "#@title Swap schedule generation and Hull-White model parameters\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "YieldParams = namedtuple('YieldParams', ['a0', 'a1', 'a2'])\n",
    "\n",
    "def random_yield_params(size, max_time=30.0):\n",
    "  r0 = dtype(np.random.rand(size)* (0.07 - 0.005) + 0.005)\n",
    "  rT = dtype(np.random.rand(size)* (0.07 - 0.005) + 0.005)\n",
    "  r_mins = np.minimum(r0, rT)\n",
    "  r_maxs = np.maximum(r0, rT)\n",
    "  do_low = np.random.rand(size) > dtype(0.5)\n",
    "  a0 = np.random.rand(size)\n",
    "  a0 = np.where(do_low, a0 * (r_mins - 0.0001) + 0.0001, a0 * (0.08 - r_maxs) + r_maxs)\n",
    "  a2 = max_time / (1 + np.random.choice([-1.0, 1.0], size=size) * np.sqrt((rT - a0)/(r0-a0)))\n",
    "  a1 = (r0 - a0) / a2 / a2\n",
    "  return YieldParams(a0=a0,a1=a1,a2=a2)\n",
    "\n",
    "def log_current_discount_fwd_fn(yield_params):\n",
    "  \"\"\"Suitable for the next log discount evaluator below.\"\"\"\n",
    "  a0 = np.array(yield_params.a0, dtype=dtype)\n",
    "  a1 = np.array(yield_params.a1, dtype=dtype)\n",
    "  a2 = np.array(yield_params.a2, dtype=dtype)\n",
    "  def eval_fn(times):\n",
    "    \"\"\"Gives the log zero coupon bond price and the instantaneous forward rate.\"\"\"\n",
    "    return -(a0 + a1 * (times - a2)**2) * times, (a0 - a1 * a2 * a2 / 3) + 3 * a1 * (times - 2 * a2 / 3) ** 2\n",
    "  return eval_fn\n",
    "\n",
    "\n",
    "HullWhiteData = namedtuple('HullWhiteData',\n",
    "                           ['mean_reversion', 'volatility',\n",
    "                            'log_discount_fwd_fn'])\n",
    "\n",
    "\n",
    "def gen_hull_white_params():\n",
    "  mean_reversion = np.random.rand() * 0.1\n",
    "  volatility = np.random.rand() * 0.3\n",
    "  present_yield_curve_params = random_yield_params(1)\n",
    "  return HullWhiteData(\n",
    "      mean_reversion=mean_reversion,\n",
    "      volatility=volatility,\n",
    "      log_discount_fwd_fn=log_current_discount_fwd_fn(present_yield_curve_params))\n",
    "  \n",
    "def generate_short_rates(initial_short_rates,\n",
    "                         hull_white_params, times, num_scenarios,\n",
    "                         dtype):\n",
    "  a = dtype(hull_white_params.mean_reversion)\n",
    "  sigma = dtype(hull_white_params.volatility)\n",
    "  def instant_forward_rate_fn(t):\n",
    "    return hull_white_params.log_discount_fwd_fn(t)[1]\n",
    "  process = tff.models.hull_white.HullWhiteModel1F(\n",
    "      mean_reversion=a, volatility=sigma,\n",
    "      instant_forward_rate_fn=instant_forward_rate_fn,\n",
    "      dtype=dtype)\n",
    "  sample_paths = process.sample_paths\n",
    "  paths = sample_paths(\n",
    "      times,\n",
    "      num_samples=num_scenarios,\n",
    "      initial_state=initial_short_rates,\n",
    "      seed=42)\n",
    "  paths = tf.squeeze(paths, axis=-1)\n",
    "  # Shape [num_times, num_samples]\n",
    "  return tf.transpose(paths)\n",
    "\n",
    "def discount_curve_at_times(\n",
    "    calc_date,\n",
    "    short_rates,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    current_disc_fwd_fn,\n",
    "    day_count,\n",
    "    mean_revs,\n",
    "    sigmas):\n",
    "  \"\"\"Computes forward discount factors.\n",
    "\n",
    "  Produces P(S, T) i.e. the discount factor as seen at time 'S' the calculation date\n",
    "  for expiry at time 'T' the evaluation date.\n",
    "\n",
    "  Time today is 0. The eval times are allowed to be negative but not the calc times\n",
    "\n",
    "  Args:\n",
    "    calc_date: current date.\n",
    "    short_rates: The short rates of shape: [N_scenarios].\n",
    "    start_date: The calculation time.\n",
    "    end_date: The evaluation dates.\n",
    "    currency_disc_fwd_fn: A callable that returns instantaneous forward rate and\n",
    "      the log-discount at the specified times. \n",
    "    mean_revs: A tensor of shape [num_currencies] The mean reversions for\n",
    "      the HW model.\n",
    "    sigmas: A tensor of same shape as mean_revs.\n",
    "  \n",
    "  Returns: A tensor of shape [end_date.shape] + [N_scenarios]\n",
    "  \"\"\"\n",
    "  # S- T\n",
    "  day_fractions = day_count(\n",
    "      start_date=start_date,\n",
    "      end_date=end_date, dtype=dtype)\n",
    "  S = day_count(\n",
    "      start_date=calc_date,\n",
    "      end_date=start_date, dtype=dtype)\n",
    "  T = day_count(\n",
    "      start_date=calc_date,\n",
    "      end_date=end_date, dtype=dtype)\n",
    "\n",
    "  b_exp = mean_revs * day_fractions  # shape [N_calc_dates, n_eval_dates]\n",
    "  b = (1 - tf.exp(-b_exp)) / mean_revs\n",
    "  lnP_p = current_disc_fwd_fn(T)[0]  # shape [n_eval_dates]\n",
    "  lnP_den, inst_fwd = current_disc_fwd_fn(S)  # output of shapes [n_calc_dates, n_eval_dates]\n",
    "  lnA = (lnP_p - lnP_den + b * inst_fwd\n",
    "         - ((sigmas * b) ** 2) * (1 - tf.exp(-2 * mean_revs * S)))\n",
    "  lnA = tf.expand_dims(lnA, axis=-1)\n",
    "  b = tf.expand_dims(b, axis=-1)\n",
    "  short_rates = tf.expand_dims(short_rates, axis=0)\n",
    "  discounts = tf.exp(lnA - b * short_rates)\n",
    "  # Adjust for when calc_date > eval_date\n",
    "  return discounts #tf.where(tf.expand_dims(T > S, -1), discounts, 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qpul0dPeODAs"
   },
   "source": [
    "# Pricing vanilla\n",
    " swaps comparison. CPU vs GPU vs TPU\n",
    "\n",
    "Note that **QuantLib** pricing speed for a swap with 40 payments:\n",
    "**10000 swaps / sec** on a Intel . TPU can price **2 million / sec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igjBC5XKtuXY"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "hull_white_params = gen_hull_white_params()\n",
    "calc_date = dates.from_year_month_day(2015, 9, 9)\n",
    "# Corresponding ql.WeekendsOnly calendar\n",
    "calendar = dates.create_holiday_calendar(\n",
    "    weekend_mask=dates.WeekendMask.SATURDAY_SUNDAY)\n",
    "# Business day convention\n",
    "bussiness_convention = dates.BusinessDayConvention.FOLLOWING\n",
    "day_count = dates.daycounts.thirty_360_isda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqxmA8JC47Y5"
   },
   "outputs": [],
   "source": [
    "# Generate swaps\n",
    "# One tenor for simplicity\n",
    "TENORS = [1, 3, 6, 12] # months\n",
    "\n",
    "NUM_SWAPS = 100000 #@param\n",
    "\n",
    "NUM_SWAPS_PER_TENOR = NUM_SWAPS // len(TENORS)\n",
    "# Start date of the swaps\n",
    "\n",
    "def generate_swaps():\n",
    "    start_dates = []\n",
    "    end_dates = []\n",
    "    schedule_dates = []\n",
    "    long_short = []\n",
    "    for t in TENORS:\n",
    "        random_shift = np.int32(t * 2 *\n",
    "                              (np.random.rand(NUM_SWAPS_PER_TENOR) - 0.5) * 50)\n",
    "        start_date = calendar.add_business_days(\n",
    "          calc_date, random_shift, roll_convention=bussiness_convention)\n",
    "        # Maximum swap tenure is 30 years\n",
    "        swap_tenure = 1 + np.int32(30 * (np.random.rand(NUM_SWAPS_PER_TENOR)))\n",
    "        period = dates.periods.PeriodTensor(swap_tenure, dates.PeriodType.YEAR)\n",
    "        end_date = calendar.add_period_and_roll(start_date, period,\n",
    "                                              bussiness_convention)\n",
    "        # Exchange schedules\n",
    "        schedule = dates.PeriodicSchedule(\n",
    "          start_date=start_date, end_date=end_date,\n",
    "          tenor=dates.periods.months(t),\n",
    "          holiday_calendar=calendar,\n",
    "          roll_convention=bussiness_convention)\n",
    "        schedule_date = schedule.dates()\n",
    "        # Record swap data\n",
    "        start_dates.append(start_date)\n",
    "        end_dates.append(end_date)\n",
    "        schedule_dates.append(schedule_date.transpose())\n",
    "        long_short.append(2 * (np.random.binomial(1, 0.48, size=random_shift.shape) - 0.5))\n",
    "    return schedule_dates, long_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2A8HblZS6-w_"
   },
   "outputs": [],
   "source": [
    "# Precompute the schedules. This is done so that we measure only the pricing\n",
    "# speed on a chosen platform\n",
    "schedule_dates_day = []\n",
    "schedule_dates_month = []\n",
    "schedule_dates_year = []\n",
    "schedule_dates, long_short = generate_swaps()\n",
    "# Extract and precompute the schedules\n",
    "for schedule in schedule_dates:\n",
    "  schedule_dates_day.append(schedule.day())\n",
    "  schedule_dates_month.append(schedule.month())\n",
    "  schedule_dates_year.append(schedule.year())\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "#schedule_dates_tpu = sess.run(schedule_dates_tpu)\n",
    "schedule_dates_day, schedule_dates_month, schedule_dates_year = sess.run(\n",
    "    [schedule_dates_day, schedule_dates_month, schedule_dates_year])\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1588591568463,
     "user": {
      "displayName": "Cyril Chimisov",
      "photoUrl": "",
      "userId": "02803093032097482871"
     },
     "user_tz": -60
    },
    "id": "Nqd-QoUg6lrc",
    "outputId": "0f32f6d9-7f5f-48f5-cf65-0d34331ad0f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DateTensor: shape=(362, 25000),\n",
       " DateTensor: shape=(122, 25000),\n",
       " DateTensor: shape=(62, 25000),\n",
       " DateTensor: shape=(32, 25000)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YEFF8RNgQ8j0"
   },
   "outputs": [],
   "source": [
    "def test_fn(core_id, inputs):\n",
    "    #schedule_dates_day, schedule_dates_month, schedule_dates_year = inputs\n",
    "    day, month, year, short_rate = inputs\n",
    "    swaps = []\n",
    "    calc_date = dates.from_year_month_day(year[core_id],\n",
    "                                          month[core_id],\n",
    "                                          day[core_id])\n",
    "    schedule_dates = []\n",
    "    for year, month, day in zip(schedule_dates_year,\n",
    "                                schedule_dates_month,\n",
    "                                schedule_dates_day):\n",
    "      schedule_dates.append(dates.from_year_month_day(year,\n",
    "                                                      month,\n",
    "                                                      day))\n",
    "    def build_discount_curve(schedule):\n",
    "      def discount_curve(d):\n",
    "        return tf.squeeze(discount_curve_at_times(\n",
    "            calc_date,\n",
    "            short_rate[core_id],\n",
    "            d,\n",
    "            schedule[1:],\n",
    "            hull_white_params.log_discount_fwd_fn,\n",
    "            day_count,\n",
    "            hull_white_params.mean_reversion,\n",
    "            hull_white_params.volatility), -1)\n",
    "      return discount_curve\n",
    "    for schedule in schedule_dates:\n",
    "\n",
    "      # Compute the float let rates\n",
    "      float_leg_rates = get_fixings(\n",
    "              dates_tensor=schedule,\n",
    "              day_count=day_count,\n",
    "              discount_fn=build_discount_curve(schedule),\n",
    "              dtype=dtype)\n",
    "      #return float_leg_rates\n",
    "      swap = VanillaSwap(\n",
    "          calc_date=calc_date,\n",
    "          fixed_leg_dates=schedule,\n",
    "          float_leg_dates=schedule,\n",
    "          fixed_leg_rates=0.0039,\n",
    "          float_leg_rates=float_leg_rates,\n",
    "          notional=1000000,\n",
    "          day_count=day_count,\n",
    "          discount_fn=build_discount_curve(schedule),\n",
    "          dtype=dtype)\n",
    "      swaps.append(swap)\n",
    "    prices = [position * swap.price()\n",
    "          for swap, position in zip(swaps, long_short)]\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0tTdZjtNsmM"
   },
   "source": [
    "#### CPU performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jMCpFr2NsmO"
   },
   "outputs": [],
   "source": [
    "NUM_SCENARIOS = 1000 #@param\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "  days = tf.compat.v1.placeholder(tf.int32, shape=[1],\n",
    "                                  name=\"days_cpu\")\n",
    "  months = tf.compat.v1.placeholder(tf.int32, shape=[1],\n",
    "                                    name=\"months_cpu\")\n",
    "  years = tf.compat.v1.placeholder(tf.int32, shape=[1],\n",
    "                                   name=\"years_cpu\")\n",
    "  def cond(iter_num, res):\n",
    "    return iter_num < NUM_SCENARIOS\n",
    "  def body(iter_num, res):\n",
    "    # Generate short rates here\n",
    "    short_rate = 0.02 + tf.random.uniform([1], dtype=dtype)\n",
    "    test_cpu = tf.xla.experimental.compile(\n",
    "        test_fn, [0, [days, months, years, short_rate]])\n",
    "    test_cpu = tf.concat(test_cpu, axis=0)\n",
    "    iter_num_float = tf.cast(iter_num, dtype=dtype)\n",
    "    return iter_num + 1, (res * iter_num_float\n",
    "                          + test_cpu) / (iter_num_float + 1)\n",
    "  with tf.device(\"/cpu:0\"):\n",
    "    test_cpu_res = tf.while_loop(cond, body,\n",
    "                                 (0, tf.zeros([NUM_SWAPS], dtype=dtype)))\n",
    "  sess_cpu = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20356,
     "status": "ok",
     "timestamp": 1588591500264,
     "user": {
      "displayName": "Cyril Chimisov",
      "photoUrl": "",
      "userId": "02803093032097482871"
     },
     "user_tz": -60
    },
    "id": "gKZpjwQtNsmS",
    "outputId": "262f6579-bf05-48fc-caee-15cbfe8727a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time (CPU):  67.58648920059204\n"
     ]
    }
   ],
   "source": [
    "# Time after optimization (run the cell twice)\n",
    "t = time.time()\n",
    "with g.as_default():\n",
    "  sess_cpu.run(test_cpu_res, feed_dict={\n",
    "      \"days_cpu:0\": [9],\n",
    "      \"months_cpu:0\": [9],\n",
    "      \"years_cpu:0\": [2015]})\n",
    "print(\"Wall time (CPU): \", time.time() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GeOnj5oRWaAp"
   },
   "source": [
    "#### GPU performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-U72743WWcuo"
   },
   "outputs": [],
   "source": [
    "NUM_SCENARIOS = 1000 #@param\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "  days = tf.compat.v1.placeholder(tf.int32, shape=[1],\n",
    "                                  name=\"days_gpu\")\n",
    "  months = tf.compat.v1.placeholder(tf.int32, shape=[1],\n",
    "                                    name=\"months_gpu\")\n",
    "  years = tf.compat.v1.placeholder(tf.int32, shape=[1],\n",
    "                                   name=\"years_gpu\")\n",
    "  def cond(iter_num, res):\n",
    "    return iter_num < NUM_SCENARIOS\n",
    "  def body(iter_num, res):\n",
    "    # Generate short rates here\n",
    "    short_rate = 0.02 + tf.random.uniform([1], dtype=dtype)\n",
    "    test_gpu = tf.xla.experimental.compile(\n",
    "        test_fn, [0, [days, months, years, short_rate]])\n",
    "    test_gpu = tf.concat(test_gpu, axis=0)\n",
    "    iter_num_float = tf.cast(iter_num, dtype=dtype)\n",
    "    return iter_num + 1, (res * iter_num_float\n",
    "                          + test_gpu) / (iter_num_float + 1)\n",
    "  with tf.device(\"/gpu:0\"):\n",
    "    test_gpu_res = tf.while_loop(cond, body,\n",
    "                                 (0, tf.zeros([NUM_SWAPS], dtype=dtype)))\n",
    "  sess_gpu = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1423,
     "status": "ok",
     "timestamp": 1588591691025,
     "user": {
      "displayName": "Cyril Chimisov",
      "photoUrl": "",
      "userId": "02803093032097482871"
     },
     "user_tz": -60
    },
    "id": "IhTZ7EV0Xp4R",
    "outputId": "92f88694-1ced-4f96-8234-ac80393d61ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time (GPU):  1.111879587173462\n"
     ]
    }
   ],
   "source": [
    "# Time after optimization (run the cell twice)\n",
    "t = time.time()\n",
    "with g.as_default():\n",
    "  sess_gpu.run(test_gpu_res, feed_dict={\n",
    "      \"days_gpu:0\": [9], \"months_gpu:0\": [9],\n",
    "      \"years_gpu:0\": [2015]})\n",
    "print(\"Wall time (GPU): \", time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 s ± 390 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "with g.as_default():\n",
    "  sess_gpu.run(test_gpu_res, feed_dict={\n",
    "      \"days_gpu:0\": [9], \"months_gpu:0\": [9],\n",
    "      \"years_gpu:0\": [2015]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5sCnM7SWXac"
   },
   "source": [
    "#### TPU performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2322,
     "status": "ok",
     "timestamp": 1588591275383,
     "user": {
      "displayName": "Cyril Chimisov",
      "photoUrl": "",
      "userId": "02803093032097482871"
     },
     "user_tz": -60
    },
    "id": "VsEyVkijRUpK",
    "outputId": "efd935fb-5ad4-41b4-8122-a782c7c3228c"
   },
   "outputs": [],
   "source": [
    "NUM_TPU_CORES =  32 #@param\n",
    "NUM_SCENARIOS= 20000 #@param\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "  days = tf.compat.v1.placeholder(tf.int32, shape=[NUM_TPU_CORES],\n",
    "                                  name=\"days_tpu\")\n",
    "  months = tf.compat.v1.placeholder(tf.int32, shape=[NUM_TPU_CORES],\n",
    "                                    name=\"months_tpu\")\n",
    "  years = tf.compat.v1.placeholder(tf.int32, shape=[NUM_TPU_CORES],\n",
    "                                   name=\"years_tpu\")\n",
    "  def cond(iter_num, res):\n",
    "    return iter_num < NUM_SCENARIOS\n",
    "  def body(iter_num, res):\n",
    "    short_rate = 0.02 + tf.random.uniform([NUM_TPU_CORES], dtype=dtype)\n",
    "    test_tpu = tf.compat.v1.tpu.replicate(\n",
    "        test_fn,\n",
    "        inputs=[\n",
    "                [core_id,\n",
    "                  [days,\n",
    "                    months,\n",
    "                    years,\n",
    "                    short_rate]\n",
    "                  ]\n",
    "                for core_id in range(NUM_TPU_CORES)])\n",
    "    test_tpu = [tf.concat(t, axis=0) for t in test_tpu]\n",
    "    test_tpu = tf.reduce_mean(test_tpu, axis=0)\n",
    "    iter_num_float = tf.cast(iter_num, dtype=dtype)\n",
    "    return (iter_num + NUM_TPU_CORES,\n",
    "            (res * iter_num_float + test_tpu)\n",
    "            / (iter_num_float + NUM_TPU_CORES))\n",
    "  test_tpu_res = tf.while_loop(cond, body,\n",
    "                               (0, tf.zeros([NUM_SWAPS], dtype=dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session():\n",
    "  def _get_tpu_setup():\n",
    "    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "        tpu=\"node-1\", zone=\"us-central1-a\")\n",
    "    cluster_def = tpu_cluster_resolver.cluster_spec().as_cluster_def()\n",
    "    tpu_master_grpc_path = tpu_cluster_resolver.get_master()\n",
    "    return cluster_def, tpu_master_grpc_path\n",
    "\n",
    "  cluster_def, tpu_master_grpc_path = _get_tpu_setup()\n",
    "  config = tf.compat.v1.ConfigProto(\n",
    "      allow_soft_placement=True,\n",
    "      isolate_session_state=True,\n",
    "      cluster_def=cluster_def)\n",
    "  return tf.compat.v1.Session(tpu_master_grpc_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12655,
     "status": "ok",
     "timestamp": 1588591118814,
     "user": {
      "displayName": "Cyril Chimisov",
      "photoUrl": "",
      "userId": "02803093032097482871"
     },
     "user_tz": -60
    },
    "id": "KLtvLkKukI_m",
    "outputId": "2410aa65-e4e7-4dea-dd6c-a1005a7c8c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\x04\\x04\\x04\\x01\\x02\\x10\\x04\\x18\\x08\"\\x80\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x01\\x01\\x01\\x00\\x00\\x01\\x01\\x00\\x01\\x02\\x02\\x00\\x00\\x02\\x02\\x00\\x01\\x03\\x02\\x00\\x00\\x03\\x02\\x00\\x01\\x02\\x03\\x00\\x00\\x02\\x03\\x00\\x01\\x03\\x03\\x00\\x00\\x03\\x03\\x00\\x01\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x01\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x01\\x02\\x01\\x00\\x00\\x02\\x01\\x00\\x01\\x03\\x01\\x00\\x00\\x03\\x01\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x01\\x01\\x02\\x00\\x00\\x01\\x02\\x00\\x01\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x01\\x01\\x03\\x00\\x00\\x01\\x03\\x00\\x01'\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "  # If running on a TPU with > 8 cores:\n",
    "  sess_tpu = get_session()\n",
    "  # If running on a small TPU:\n",
    "  # internal_ip = \"10.107.181.26\"\n",
    "  # sess_tpu = tf.compat.v1.Session(\"grpc://{}:8470\".format(internal_ip))\n",
    "  print(sess_tpu.run(tf.compat.v1.tpu.initialize_system()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time (TPU 32 cores, 20k scenarios):  3.1102778911590576\n"
     ]
    }
   ],
   "source": [
    "# Time after optimization (run the cell twice)\n",
    "t = time.time()\n",
    "with g.as_default():\n",
    "  sess_tpu.run(test_tpu_res, feed_dict={\"days_tpu:0\": NUM_TPU_CORES * [9],\n",
    "                                        \"months_tpu:0\": NUM_TPU_CORES * [9],\n",
    "                                        \"years_tpu:0\": NUM_TPU_CORES * [2015]})\n",
    "print(\"Wall time (TPU 32 cores, 20k scenarios): \", time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1588591334480,
     "user": {
      "displayName": "Cyril Chimisov",
      "photoUrl": "",
      "userId": "02803093032097482871"
     },
     "user_tz": -60
    },
    "id": "-qdgAyReKRoE",
    "outputId": "1e5954e7-e280-4bca-eca4-8bc2881b43f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time:  0.29540467262268066\n"
     ]
    }
   ],
   "source": [
    "# Time after optimization (run the cell twice)\n",
    "t = time.time()\n",
    "with g.as_default():\n",
    "  sess_tpu.run(test_tpu_res, feed_dict={\"days_tpu:0\": NUM_TPU_CORES * [9],\n",
    "                                        \"months_tpu:0\": NUM_TPU_CORES * [9],\n",
    "                                        \"years_tpu:0\": NUM_TPU_CORES * [2015]})\n",
    "print(\"Wall time (TPU 8 cores, 1k scenarios): \", time.time() - t)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Qpul0dPeODAs",
    "pz3_zhvFKeWy"
   ],
   "last_runtime": {
    "build_target": "//learning/deepmind/dm_python:dm_notebook3",
    "kind": "private"
   },
   "name": "Swap_pricing_on_a_TPU.ipynb",
   "provenance": [
    {
     "file_id": "1fi1DZel9h6AuAgAYlPEEg6kpeffz_xhc",
     "timestamp": 1588586769338
    },
    {
     "file_id": "1jfaCMQ-pgi9YvyJUntj_6RKhNrS2A6Dd",
     "timestamp": 1587137295155
    }
   ]
  },
  "environment": {
   "name": "tf2-gpu.2-1.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
